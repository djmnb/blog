---
title: java常用库
date: 2023-2-17
---

## 前言

记录一下java的一些库可以用来处理哪些东西,这里还附上[Maven仓库地址](https://mvnrepository.com/artifact/org.jsoup/jsoup)

## 处理文档

Java提取文档中的数据的方法取决于文档的类型和数据的格式。下面列出了一些可能用到的Java库和工具以及它们支持的数据类型：

1. Apache POI：POI是一种流行的Java库，用于处理Microsoft Office格式的文档，如Word文档（.docx）、Excel文档（.xlsx）和PowerPoint演示文稿（.pptx）。
2. PDFBox：PDFBox是一个用于创建和处理PDF文档的Java库。它可以用于提取PDF文档中的文本和元数据。
3. jTidy：jTidy是一个用于清理和解析HTML文档的Java库。它可以将HTML文档转换为XHTML格式，从而更容易地提取其中的数据。
4. **Jsoup**：Jsoup是另一个用于解析HTML文档的Java库。它提供了一种简单的方式来解析HTML文档，并提取其中的数据。
5. OpenCSV：OpenCSV是一个Java库，用于读写CSV文件。如果您需要从CSV文件中提取数据，则可以使用OpenCSV。
6. **JSON**：JSON是一种轻量级数据交换格式，可用于表示复杂的数据结构。Java有很多库可用于解析和处理JSON数据，如Jackson和Gson。
7. XML：XML是一种常见的数据格式，可以用于表示各种数据类型。Java有内置的XML解析器，如DOM和SAX，可以用于解析和处理XML数据。
8. **正则表达式**：如果您需要从文本文件中提取特定的数据，您可以使用Java的正则表达式库。正则表达式是一种强大的模式匹配工具，可用于从文本中提取特定的数据。

## 爬虫

Java 中有很多流行的爬虫库可供选择，以下是其中一些比较好用的爬虫库：

1. Jsoup：Jsoup 是一款用于解析 HTML 和 XML 文档的 Java 库，它可以方便地从网页中提取数据，并支持 CSS 选择器语法。
2. Apache Nutch：Apache Nutch 是一款基于 Java 的开源网络爬虫，它可以处理大规模的网页抓取任务，并提供了一套强大的数据处理和索引技术。
3. **WebMagic**：WebMagic 是一款非常强大的开源网络爬虫框架，它基于 Java 实现，使用简单、灵活，可以实现高效的网页抓取和数据解析。
4. Crawler4j：Crawler4j 是一款基于 Java 的高效 Web 爬虫框架，它可以在多线程环境下处理大规模的网页抓取任务，并支持多种配置和插件扩展。
5. HtmlUnit：HtmlUnit 是一款基于 Java 的无头浏览器库，它可以模拟浏览器的行为并执行 JavaScript，支持多种浏览器标准和 CSS 选择器语法。
6. Jaunt：Jaunt 是一款易于使用的 Java 网络爬虫库，它可以模拟浏览器的行为、自动填充表单并提取网页数据，支持 JavaScript 和 AJAX。

这些爬虫库都有其优点和适用场景，选择哪一个取决于你的具体需求。